---
title: "ML_Coursera"
author: "Scott Jacobs"
date: "December 22, 2015"
output: html_document
---
##Background

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset). 

##Project Results


Below are the dimensions of the Train and Test files respectively. Note: We have coerced to NA any missing, #DIV/0!, or NAs to NA.

###Data Read
```{r Data_Read}
#install.packages(c("doParallel", "parallel", "caret", "data.table")
###########################Read in Data##############################
library(caret)
library(data.table)
#create vector of strings that should be coerced to NA by the fread()
NAs <- c("", "NA", "#DIV/0!")
#establish URLs
trainUrl <-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
#read URLs into objects
trainFile <- fread(trainUrl, na.strings = NAs, data.table=FALSE)
testFile  <- fread(testUrl, na.strings = NAs, data.table=FALSE)
dim(trainFile)
dim(testFile)
```

It's now time to clean up the data. We only keep cols with less than 10% NA. 

Below are the dimensions of the Train file after it has been cleaned up. It got rid of quite a few cols.

We then check for near zero variance as well as co-linearity. No linear combinations were found. 

###Clean Data
```{r Tidy_Data, echo=FALSE}
############################ Tidy Data ################################
#keep only columns with less than 10% NAs
trainFile <- trainFile[, colSums(is.na(trainFile)) <= .1*(nrow(trainFile))]
testFile <- testFile[, colSums(is.na(testFile)) <= .1*(nrow(testFile))]
#turn Classe into a factor variable so predictions work
trainFile$classe <- factor(trainFile$classe)

#check for non-zero variance
nzv <- nearZeroVar(trainFile)
trainFile <- trainFile[, -nzv]
#check dimensions - i wish more people did this
dim(trainFile)

#This only works for matrices
#create numeric matrix of training data, remove non-numeric variables
m <- trainFile[,-1:-6]
#remove classe
m1 <- m[,-53]
trainingProc <- m1
descrCor <-  cor(m1)
#highCorr <- sum(abs(m[upper.tri(m1)]) > .999)
#summary(descrCor[upper.tri(descrCor)])

highlyCorDescr <- findCorrelation(descrCor, cutoff = .75)
trainingProc <- m1[,-highlyCorDescr]
descrCor2 <- cor(m1)
#summary(descrCor2[upper.tri(descrCor2)])
#library(corrplot)
#plot correlations
#corrplot(descrCor2)

#check for linear dependencies
comboInfo <- findLinearCombos(m1)
#no linear combos found

```

We create two smaller data sets from the Training file for cross-validation; 

1.) training and 2.) probing. 

Training will be used to fit the model. 
Probing will be used to verify the results.

###Data Splitting and Pre-Processing
```{r PreProc_DataSplit}
################## Pre-Proc, Data Splitting ####################### 
preProcValues <- preProcess(trainingProc, method = c("center", "scale"))
#use the pre-processed values to transform the training data
trainTransformed <- predict(preProcValues, trainFile)
testTransformed <- predict(preProcValues, testFile)
#add back in classe to the training data, keep only the cols we used in preProc
trainTransformed <- trainTransformed[,c(names(trainingProc),"classe")]
testTransformed <- testTransformed[,c(names(trainingProc))]

set.seed(545)
#create training and probing sets from the original training set
TrainRows <- createDataPartition(y=trainTransformed$classe, p=.7, list=F)
training <- trainTransformed[TrainRows,]
probing <- trainTransformed[-TrainRows,]
dim(training)
dim(probing)
```

We are using the random forest model along with K-Folds (10) cross-validation. The model is then used to predict on the probing data set.

###Model Building
```{r ModelBuilding}
########################## Model Building #########################
#Let's make this go faster
require(parallel)
require(doParallel)
cores <- makeCluster(detectCores() - 1)
registerDoParallel(cores)


#create Random Forrest Model, use k-folds cross validation (10 folds)
#use the training set we just created from the partitioned data above
modFit <- train(classe ~ ., data = training, 
                method = "rf", trControl = trainControl(method = "repeatedcv", repeats = 10))
#identify important variables
importance <- varImp(modFit, scale = FALSE)
#plot the top 10 important variables
plot(importance, top = 10)
#review the model
summary(modFit) 
#validate the model with the probing data set we created in the partition
pred <- predict(modFit, probing)
summary(pred)
stopCluster(cores)
```

The results of the in sample error rate are represented by the call to modFit. The out of sample error rate is given by calling the confusion matrix on the probing data. The error is very low in both cases, and even lower in the final fitted model. This is unusual but the instructors likely made this a very "solvable" problem :)

###Results
```{r Results}
############################## Results ################################
#Here are the in sample error rates
modFit
#Here are the out of sample error rates
confusionMatrix(pred, probing$classe)
#predict classe using the mdoel on the test data
predTest <- predict(modFit, testTransformed)
summary(predTest)
```

